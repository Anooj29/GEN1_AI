{"cells":[{"cell_type":"markdown","id":"c0ad8755-8b97-4ba2-8077-feaab4e67120","metadata":{},"source":["<p style=\"text-align:center\">\n","    <a href=\"https://skills.network\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","id":"ed575bab-02c5-4413-a2c5-32f19b057fd0","metadata":{},"source":["# **Regression Trees**\n"]},{"cell_type":"markdown","id":"8499c478-5cf0-48c1-9682-75b6202a6f92","metadata":{},"source":["Estimated time needed: **20** minutes\n"]},{"cell_type":"markdown","id":"833a3b9c-19d3-4f1f-8b92-144e630473a4","metadata":{},"source":["In this lab you will learn how to implement regression trees using ScikitLearn. We will show what parameters are important, how to train a regression tree, and finally how to determine our regression trees accuracy.\n"]},{"cell_type":"markdown","id":"5aeef315-a125-4fd2-8c2c-6dada7823042","metadata":{},"source":["## Objectives\n"]},{"cell_type":"markdown","id":"154e23dc-d519-4036-b761-a2dee369e7be","metadata":{},"source":["After completing this lab you will be able to:\n"]},{"cell_type":"markdown","id":"a82124ea-309b-4eaf-8b7e-e1ddb9d14080","metadata":{},"source":["* Train a Regression Tree\n","* Evaluate a Regression Trees Performance\n"]},{"cell_type":"markdown","id":"cf0184a5-3fef-466f-9379-9d1b7d49075b","metadata":{},"source":["----\n"]},{"cell_type":"markdown","id":"5595e267-c0cb-4b2b-80c4-a5a9773de994","metadata":{},"source":["## Setup\n"]},{"cell_type":"markdown","id":"9fb5180c-fb19-4067-8c6d-fc341d14b68f","metadata":{},"source":["For this lab, we are going to be using Python and several Python libraries. Some of these libraries might be installed in your lab environment or in SN Labs. Others may need to be installed by you. The cells below will install these libraries when executed.\n"]},{"cell_type":"code","execution_count":null,"id":"f867f02c-e05f-4a4a-84e6-2af7b6c62dd9","metadata":{},"outputs":[],"source":["# Install libraries not already in the environment using pip\n","#!pip install pandas==1.3.4\n","#!pip install sklearn==0.20.1"]},{"cell_type":"code","execution_count":2,"id":"42e748ae-a5c5-4fb3-8bb9-e98ff2eab62c","metadata":{},"outputs":[],"source":["# Pandas will allow us to create a dataframe of the data so it can be used and manipulated\n","import pandas as pd\n","# Regression Tree Algorithm\n","from sklearn.tree import DecisionTreeRegressor\n","# Split our data into a training and testing data\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","id":"f0bb43f4-b155-42e9-901d-5dc3f46aaf8e","metadata":{},"source":["## About the Dataset\n"]},{"cell_type":"markdown","id":"f1bed413-9dbd-466e-87b1-9a501559c152","metadata":{},"source":["Imagine you are a data scientist working for a real estate company that is planning to invest in Boston real estate. You have collected information about various areas of Boston and are tasked with created a model that can predict the median price of houses for that area so it can be used to make offers.\n","\n","The dataset had information on areas/towns not individual houses, the features are\n","\n","CRIM: Crime per capita\n","\n","ZN: Proportion of residential land zoned for lots over 25,000 sq.ft.\n","\n","INDUS: Proportion of non-retail business acres per town\n","\n","CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n","\n","NOX: Nitric oxides concentration (parts per 10 million)\n","\n","RM: Average number of rooms per dwelling\n","\n","AGE: Proportion of owner-occupied units built prior to 1940\n","\n","DIS: Weighted distances to ﬁve Boston employment centers\n","\n","RAD: Index of accessibility to radial highways\n","\n","TAX: Full-value property-tax rate per $10,000\n","\n","PTRAIO: Pupil-teacher ratio by town\n","\n","LSTAT: Percent lower status of the population\n","\n","MEDV: Median value of owner-occupied homes in $1000s\n"]},{"cell_type":"markdown","id":"ebf41f58-6465-44c8-a975-2ffd1c2eb73a","metadata":{},"source":["## Read the Data\n"]},{"cell_type":"markdown","id":"39549fe4-5d5d-40b9-a879-df93660d224c","metadata":{},"source":["Lets read in the data we have downloaded\n"]},{"cell_type":"code","execution_count":6,"id":"906b2cb2-6509-4360-8559-6bb86fb5f1c9","metadata":{},"outputs":[],"source":["data = pd.read_csv(\"C:\\\\GEN1_Artificial_Intelligence\\\\Dataset\\\\real_estate_data.csv\")"]},{"cell_type":"code","execution_count":7,"id":"7f29b4cc-962d-4540-9560-fe504c47deda","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CRIM</th>\n","      <th>ZN</th>\n","      <th>INDUS</th>\n","      <th>CHAS</th>\n","      <th>NOX</th>\n","      <th>RM</th>\n","      <th>AGE</th>\n","      <th>DIS</th>\n","      <th>RAD</th>\n","      <th>TAX</th>\n","      <th>PTRATIO</th>\n","      <th>LSTAT</th>\n","      <th>MEDV</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.00632</td>\n","      <td>18.0</td>\n","      <td>2.31</td>\n","      <td>0.0</td>\n","      <td>0.538</td>\n","      <td>6.575</td>\n","      <td>65.2</td>\n","      <td>4.0900</td>\n","      <td>1</td>\n","      <td>296</td>\n","      <td>15.3</td>\n","      <td>4.98</td>\n","      <td>24.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.02731</td>\n","      <td>0.0</td>\n","      <td>7.07</td>\n","      <td>0.0</td>\n","      <td>0.469</td>\n","      <td>6.421</td>\n","      <td>78.9</td>\n","      <td>4.9671</td>\n","      <td>2</td>\n","      <td>242</td>\n","      <td>17.8</td>\n","      <td>9.14</td>\n","      <td>21.6</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.02729</td>\n","      <td>0.0</td>\n","      <td>7.07</td>\n","      <td>0.0</td>\n","      <td>0.469</td>\n","      <td>7.185</td>\n","      <td>61.1</td>\n","      <td>4.9671</td>\n","      <td>2</td>\n","      <td>242</td>\n","      <td>17.8</td>\n","      <td>4.03</td>\n","      <td>34.7</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.03237</td>\n","      <td>0.0</td>\n","      <td>2.18</td>\n","      <td>0.0</td>\n","      <td>0.458</td>\n","      <td>6.998</td>\n","      <td>45.8</td>\n","      <td>6.0622</td>\n","      <td>3</td>\n","      <td>222</td>\n","      <td>18.7</td>\n","      <td>2.94</td>\n","      <td>33.4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.06905</td>\n","      <td>0.0</td>\n","      <td>2.18</td>\n","      <td>0.0</td>\n","      <td>0.458</td>\n","      <td>7.147</td>\n","      <td>54.2</td>\n","      <td>6.0622</td>\n","      <td>3</td>\n","      <td>222</td>\n","      <td>18.7</td>\n","      <td>NaN</td>\n","      <td>36.2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n","0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296     15.3   \n","1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242     17.8   \n","2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242     17.8   \n","3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222     18.7   \n","4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622    3  222     18.7   \n","\n","   LSTAT  MEDV  \n","0   4.98  24.0  \n","1   9.14  21.6  \n","2   4.03  34.7  \n","3   2.94  33.4  \n","4    NaN  36.2  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"markdown","id":"c6188f8a-fce7-4123-8038-551cfa701450","metadata":{},"source":["Now lets learn about the size of our data, there are 506 rows and 13 columns\n"]},{"cell_type":"code","execution_count":8,"id":"b049b9f5-b0b9-4d3c-9ca4-d47151690d96","metadata":{},"outputs":[{"data":{"text/plain":["(506, 13)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["data.shape"]},{"cell_type":"markdown","id":"bf668c7a-31ab-494c-8b3d-7196aa7d7db5","metadata":{},"source":["Most of the data is valid, there are rows with missing values which we will deal with in pre-processing\n"]},{"cell_type":"code","execution_count":9,"id":"190d749b-fd37-4da5-9e47-17896dc58448","metadata":{},"outputs":[{"data":{"text/plain":["CRIM       20\n","ZN         20\n","INDUS      20\n","CHAS       20\n","NOX         0\n","RM          0\n","AGE        20\n","DIS         0\n","RAD         0\n","TAX         0\n","PTRATIO     0\n","LSTAT      20\n","MEDV        0\n","dtype: int64"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["data.isna().sum()"]},{"cell_type":"markdown","id":"8ac246a4-2bf2-41ef-ae20-c8fb94afa75a","metadata":{},"source":["## Data Pre-Processing\n"]},{"cell_type":"markdown","id":"d0c70b68-6744-44ae-b488-63d7d60cb2cd","metadata":{},"source":["First lets drop the rows with missing values because we have enough data in our dataset\n"]},{"cell_type":"code","execution_count":10,"id":"bd28e2c0-5b0b-411f-9012-226426b5c9e1","metadata":{},"outputs":[],"source":["data.dropna(inplace=True)"]},{"cell_type":"markdown","id":"7a79790b-8e9f-46cf-8b93-79008c0ff44c","metadata":{},"source":["Now we can see our dataset has no missing values\n"]},{"cell_type":"code","execution_count":11,"id":"879c5378-6fb2-45ed-992a-7447634e1f4e","metadata":{},"outputs":[{"data":{"text/plain":["CRIM       0\n","ZN         0\n","INDUS      0\n","CHAS       0\n","NOX        0\n","RM         0\n","AGE        0\n","DIS        0\n","RAD        0\n","TAX        0\n","PTRATIO    0\n","LSTAT      0\n","MEDV       0\n","dtype: int64"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["data.isna().sum()"]},{"cell_type":"markdown","id":"226398cb-146e-4f0c-9244-c31b974e6d7d","metadata":{},"source":["Lets split the dataset into our features and what we are predicting (target)\n"]},{"cell_type":"code","execution_count":12,"id":"39ca2cd0-99e5-420c-8cdb-ec0755a05267","metadata":{},"outputs":[],"source":["X = data.drop(columns=[\"MEDV\"])\n","Y = data[\"MEDV\"]"]},{"cell_type":"code","execution_count":13,"id":"82688cb1-3bd3-4ec3-8707-b647beed6ed0","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CRIM</th>\n","      <th>ZN</th>\n","      <th>INDUS</th>\n","      <th>CHAS</th>\n","      <th>NOX</th>\n","      <th>RM</th>\n","      <th>AGE</th>\n","      <th>DIS</th>\n","      <th>RAD</th>\n","      <th>TAX</th>\n","      <th>PTRATIO</th>\n","      <th>LSTAT</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.00632</td>\n","      <td>18.0</td>\n","      <td>2.31</td>\n","      <td>0.0</td>\n","      <td>0.538</td>\n","      <td>6.575</td>\n","      <td>65.2</td>\n","      <td>4.0900</td>\n","      <td>1</td>\n","      <td>296</td>\n","      <td>15.3</td>\n","      <td>4.98</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.02731</td>\n","      <td>0.0</td>\n","      <td>7.07</td>\n","      <td>0.0</td>\n","      <td>0.469</td>\n","      <td>6.421</td>\n","      <td>78.9</td>\n","      <td>4.9671</td>\n","      <td>2</td>\n","      <td>242</td>\n","      <td>17.8</td>\n","      <td>9.14</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.02729</td>\n","      <td>0.0</td>\n","      <td>7.07</td>\n","      <td>0.0</td>\n","      <td>0.469</td>\n","      <td>7.185</td>\n","      <td>61.1</td>\n","      <td>4.9671</td>\n","      <td>2</td>\n","      <td>242</td>\n","      <td>17.8</td>\n","      <td>4.03</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.03237</td>\n","      <td>0.0</td>\n","      <td>2.18</td>\n","      <td>0.0</td>\n","      <td>0.458</td>\n","      <td>6.998</td>\n","      <td>45.8</td>\n","      <td>6.0622</td>\n","      <td>3</td>\n","      <td>222</td>\n","      <td>18.7</td>\n","      <td>2.94</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.02985</td>\n","      <td>0.0</td>\n","      <td>2.18</td>\n","      <td>0.0</td>\n","      <td>0.458</td>\n","      <td>6.430</td>\n","      <td>58.7</td>\n","      <td>6.0622</td>\n","      <td>3</td>\n","      <td>222</td>\n","      <td>18.7</td>\n","      <td>5.21</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n","0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296     15.3   \n","1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242     17.8   \n","2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242     17.8   \n","3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222     18.7   \n","5  0.02985   0.0   2.18   0.0  0.458  6.430  58.7  6.0622    3  222     18.7   \n","\n","   LSTAT  \n","0   4.98  \n","1   9.14  \n","2   4.03  \n","3   2.94  \n","5   5.21  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["X.head()"]},{"cell_type":"code","execution_count":14,"id":"0d4ee0af-d37f-4e79-b09e-eea46f0fe598","metadata":{},"outputs":[{"data":{"text/plain":["0    24.0\n","1    21.6\n","2    34.7\n","3    33.4\n","5    28.7\n","Name: MEDV, dtype: float64"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["Y.head()"]},{"cell_type":"markdown","id":"75ec2742-888e-499a-aea2-ac255ac1b58d","metadata":{},"source":["Finally lets split our data into a training and testing dataset using `train_test_split` from `sklearn.model_selection`\n"]},{"cell_type":"code","execution_count":15,"id":"6d3ce35e-e2a0-41ad-a506-bd99068338a6","metadata":{},"outputs":[],"source":["X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=1)"]},{"cell_type":"markdown","id":"bcc9dfe5-68c9-4e98-bcfb-bc9dcfaedb84","metadata":{},"source":["## Create Regression Tree\n"]},{"cell_type":"markdown","id":"62bd6dcf-3762-4b68-9861-5c3f9aef85dd","metadata":{},"source":["Regression Trees are implemented using `DecisionTreeRegressor` from `sklearn.tree`\n","\n","The important parameters of `DecisionTreeRegressor` are\n","\n","`criterion`: {\"mse\", \"friedman_mse\", \"mae\", \"poisson\"} - The function used to measure error\n","\n","`max_depth` - The max depth the tree can be\n","\n","`min_samples_split` - The minimum number of samples required to split a node\n","\n","`min_samples_leaf` - The minimum number of samples that a leaf can contain\n","\n","`max_features`: {\"auto\", \"sqrt\", \"log2\"} - The number of feature we examine looking for the best one, used to speed up training\n"]},{"cell_type":"markdown","id":"4f6fd6ac-e155-4f6f-8144-83db47accb86","metadata":{},"source":["First lets start by creating a `DecisionTreeRegressor` object,  setting the `criterion` parameter to `mse` for  Mean Squared Error\n"]},{"cell_type":"code","execution_count":18,"id":"7c41b5fc-cc6a-4617-8c97-6a668ae686e9","metadata":{},"outputs":[],"source":["regression_tree = DecisionTreeRegressor(criterion = 'mse')"]},{"cell_type":"markdown","id":"bed5ee57-d52c-4c72-b30e-7afb1e3ea793","metadata":{},"source":["## Training\n"]},{"cell_type":"markdown","id":"f47f87cb-d4a3-4094-9960-cf62ed2f7911","metadata":{},"source":["Now lets train our model using the `fit` method on the `DecisionTreeRegressor` object providing our training data\n"]},{"cell_type":"code","execution_count":20,"id":"4d57ac88-08f6-41b7-acab-41a5ca5b5792","metadata":{},"outputs":[{"ename":"InvalidParameterError","evalue":"The 'criterion' parameter of DecisionTreeRegressor must be a str among {'poisson', 'friedman_mse', 'squared_error', 'absolute_error'}. Got 'mse' instead.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)","Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mregression_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mX_train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mY_train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\Anooj Dilip Archana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1466\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1461\u001b[0m partial_fit_and_fitted \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1462\u001b[0m     fit_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[0;32m   1463\u001b[0m )\n\u001b[0;32m   1465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[1;32m-> 1466\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[0;32m   1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\Anooj Dilip Archana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:666\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    659\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[0;32m    660\u001b[0m \n\u001b[0;32m    661\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 666\u001b[0m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\Anooj Dilip Archana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m     )\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m )\n","\u001b[1;31mInvalidParameterError\u001b[0m: The 'criterion' parameter of DecisionTreeRegressor must be a str among {'poisson', 'friedman_mse', 'squared_error', 'absolute_error'}. Got 'mse' instead."]}],"source":["regression_tree.fit(X_train, Y_train)"]},{"cell_type":"markdown","id":"309d352e-1185-46ab-8cbc-96b5f14e3f6e","metadata":{},"source":["## Evaluation\n"]},{"cell_type":"markdown","id":"6b32ac69-16c7-4a6c-b038-5ec72b58ffab","metadata":{},"source":["To evaluate our dataset we will use the `score` method of the `DecisionTreeRegressor` object providing our testing data, this number is the $R^2$ value which indicates the coefficient of determination\n"]},{"cell_type":"code","execution_count":21,"id":"5db8c08b-bb6d-40e7-b40e-6554c8f5cb13","metadata":{},"outputs":[{"ename":"NotFittedError","evalue":"This DecisionTreeRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mregression_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\Anooj Dilip Archana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:848\u001b[0m, in \u001b[0;36mRegressorMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the coefficient of determination of the prediction.\u001b[39;00m\n\u001b[0;32m    807\u001b[0m \n\u001b[0;32m    808\u001b[0m \u001b[38;5;124;03mThe coefficient of determination :math:`R^2` is defined as\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;124;03m:class:`~sklearn.multioutput.MultiOutputRegressor`).\u001b[39;00m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n\u001b[1;32m--> 848\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r2_score(y, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n","File \u001b[1;32mc:\\Users\\Anooj Dilip Archana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:528\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    506\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict class or regression value for X.\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03m    For a classification model, the predicted class for each sample in X is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[38;5;124;03m        The predicted classes, or the predict values.\u001b[39;00m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 528\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    529\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X, check_input)\n\u001b[0;32m    530\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_\u001b[38;5;241m.\u001b[39mpredict(X)\n","File \u001b[1;32mc:\\Users\\Anooj Dilip Archana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1661\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n","\u001b[1;31mNotFittedError\u001b[0m: This DecisionTreeRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."]}],"source":["regression_tree.score(X_test, Y_test)"]},{"cell_type":"markdown","id":"31274527-03bc-4b0a-bfe1-016c2f27963c","metadata":{},"source":["We can also find the average error in our testing set which is the average error in median home value prediction\n"]},{"cell_type":"code","execution_count":null,"id":"29d19c03-bac9-4bf7-b602-a007c6cbedcc","metadata":{},"outputs":[],"source":["prediction = regression_tree.predict(X_test)\n","\n","print(\"$\",(prediction - Y_test).abs().mean()*1000)"]},{"cell_type":"markdown","id":"15c3e467-a253-4532-9dc7-a73a53bfdca9","metadata":{},"source":["## Excercise\n"]},{"cell_type":"markdown","id":"a41af9c9-2d60-47f7-810b-7a2001cecb81","metadata":{},"source":["Train a regression tree using the `criterion` `mae` then report its $R^2$ value and average error\n"]},{"cell_type":"code","execution_count":null,"id":"9ca0b569-36bf-40ec-b8ae-9b509c14eb75","metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","id":"06a58777-9654-4c0d-b125-17338ad2bb26","metadata":{},"source":["<details><summary>Click here for the solution</summary>\n","\n","```python\n","regression_tree = DecisionTreeRegressor(criterion = \"mae\")\n","\n","regression_tree.fit(X_train, Y_train)\n","\n","print(regression_tree.score(X_test, Y_test))\n","\n","prediction = regression_tree.predict(X_test)\n","\n","print(\"$\",(prediction - Y_test).abs().mean()*1000)\n","\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","id":"5dd5011c-7d00-418d-a42c-c0ff3f6bdec3","metadata":{},"source":["## Authors\n"]},{"cell_type":"markdown","id":"1772ad6a-d234-4101-bd32-161aac675ce8","metadata":{},"source":["Azim Hirjani\n"]},{"cell_type":"markdown","id":"aed4efe8-1d3f-47f7-8982-cc43fa3f8308","metadata":{},"source":["## Change Log\n"]},{"cell_type":"markdown","id":"46d17e22-4fba-4f3c-b912-0180a78fe52b","metadata":{},"source":["|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n","|-|-|-|-|\n","|2020-07-20|0.2|Azim|Modified Multiple Areas|\n","|2020-07-17|0.1|Azim|Created Lab Template|\n"]},{"cell_type":"markdown","id":"c51c0ff1-980c-475a-87ed-2d32a9e1a209","metadata":{},"source":["Copyright © 2020 IBM Corporation. All rights reserved.\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
